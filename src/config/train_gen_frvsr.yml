# basic configs
scale: 4
manual_seed: 0
verbose: true
gt_bit_depth: 8

# dataset configs
dataset:
  degradation:
    type: BI
    sigma: 1.5

  train:
    name: Vimeo90K_train
    gt_seq_dir: datasets/Vimeo90K/lmdb/V90K_train_GT.lmdb
    lr_seq_dir: datasets/Vimeo90K/lmdb/V90K_train_LR_BI.lmdb
    # gt_seq_dir: ../data/RPO_UHD_16.lmdb   # PairedLmdbDataset
    # lr_seq_dir: ../data/RPO_DVD_16.lmdb   # PairedFolderDataset
    filter_file: ~
    data_type: rgb
    gt_crop_size: 192
    batch_size: 8
    num_workers: 0
    pin_memory: true
    clip_length: 7

  test:
    name: Vimeo90K_val
    gt_seq_dir: datasets/Vimeo90K/lmdb/V90K_val_GT.lmdb
    lr_seq_dir: datasets/Vimeo90K/lmdb/V90K_val_LR_BI.lmdb
    # gt_seq_dir: ../data/transformers_light_UHD.lmdb  # PairedLmdbDataset
    # lr_seq_dir: ../data/transformers_light_DVD.lmdb
    # gt_seq_dir: ../data/Transformers_light/UHD  # PairedFolderDataset
    # lr_seq_dir: ../data/Transformers_light/DVD
    filter_file: ~
    data_type: rgb
    num_workers: 0
    pin_memory: true
    clip_length: 7

  # test_vid4:
  #   name: Vid4
  #   gt_seq_dir: C:/Users/aleft/Documents/vsr_datasets/Vid4/GT  
  #   lr_seq_dir: C:/Users/aleft/Documents/vsr_datasets/Vid4/BIx4
  #   # gt_seq_dir: ../data/transformers_light_UHD.lmdb  # PairedLmdbDataset
  #   # lr_seq_dir: ../data/transformers_light_DVD.lmdb
  #   # gt_seq_dir: ../data/Transformers_light/UHD  # PairedFolderDataset
  #   # lr_seq_dir: ../data/Transformers_light/DVD
  #   filter_file: ~
  #   num_workers: 0
  #   pin_memory: true
  #   clip_length: 24


# model configs
model:
  name: FRVSR

  generator:
    name: EGVSR # efficient GAN-based generator
    in_nc: 3
    out_nc: 3
    nf: 64
    nb: 16
    upsample_func: bilinear
    transp_conv: False
    load_path: ~
    # reconstruction_path: ~
    reconstruction_path: experiments/srresnet_16/train/ckpt/G_iter170000.pth
    # nb: 10
    # load_path: pretrained_models/EGVSR_iter420000.pth

  discriminator:
    name: None
    in_nc: 3
    tempo_range: 3
    load_path: ~


# training configs
train:
  tempo_extent: 7
  start_iter: 0
  total_iter: 100000

  # configs for generator
  generator:
    lr: !!float 5e-5
    lr_schedule:
      type: MultiStepLR
      milestones: [50000]
      gamma: 0.5
    beta1: 0.9
    beta2: 0.999

  # configs for discriminator
  discriminator:
    update_policy: adaptive
    update_threshold: 0.4
    crop_border_ratio: 0.75
    lr: !!float 5e-5
    lr_schedule:
      type: FixedLR
    beta1: 0.9
    beta2: 0.999

  # other configs
  moving_first_frame: true
  moving_factor: 0.7

  # criterions
  pixel_crit:
    type: CB
    weight: 1
    reduction: mean

  warping_crit:
    type: CB
    weight: 1
    reduction: mean

  feature_crit:
    type: L1
    weight: 0.01
    reduction: mean
    feature_layers: [2, 7, 16, 25, 34]  # "conv1_2", "conv2_2", "conv3_4", "conv4_4", "conv5_4" - before ReLU
    feature_weights: [0.1, 0.1, 1, 1, 1]

  ### From FeiFei article
  # We train models to perform ×4 and ×8 super-resolution by
  # minimizing feature reconstruction loss at layer relu2_2 from the VGG-16 loss
  #######################

  # pingpong_crit:
  #   type: CB
  #   weight: 0.5
  #   reduction: mean

  # gan_crit:
  #   type: GAN
  #   weight: 0.01
  #   reduction: mean


# validation configs
test:
  tempo_extent: 7
  test_freq: 10000

  # whether to save the generated SR results
  save_res: false
  res_dir: ~   # use default dir

  # whether to save the test results in a json file
  save_json: true
  json_dir: ~  # use default dir

  padding_mode: reflect
  num_pad_front: 5


# metric configs
metric:
  PSNR:
    colorspace: y
    mult: 1.0

  SSIM:
    mult: 1.0

  LPIPS:
    model: net-lin
    net: alex
    colorspace: rgb
    spatial: false
    version: 0.1
    mult: 1.0

  # tOF:
  #   mult: 1.0


# logger configs
logger:
  tb_freq: 1000
  log_freq: 100
  decay: 0.99
  ckpt_freq: 10000